{"cells": [{"cell_type": "code", "execution_count": null, "id": "9cec8a31-4c08-4126-9b72-4507b92afbec", "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "from torch.utils.data import DataLoader\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import matplotlib.gridspec as gridspec\n", "import seaborn as sns\n", "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, recall_score, precision_score, confusion_matrix\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.preprocessing import label_binarize\n", "from sklearn.utils import resample\n", "from scipy.stats import sem, t\n", "from scipy import io\n", "from collections import defaultdict\n", "import os\n", "import re\n", "import itertools\n", "import random"]}, {"cell_type": "code", "execution_count": null, "id": "6321892b-09ff-47db-82f4-2d9cd490a525", "metadata": {}, "outputs": [], "source": ["def find_optimal_cutoff(tpr, fpr, thresholds):\n", "    \"\"\"Find the optimal cutoff point from ROC curve.\"\"\"\n", "    j_scores = tpr - fpr\n", "    j_ordered = sorted(zip(j_scores, thresholds))\n", "    return j_ordered[-1][1]\n", "def bootstrap_auc(y_true, y_pred, n_bootstraps=2000, rng_seed=42):\n", "    n_bootstraps = n_bootstraps\n", "    rng_seed = rng_seed  \n", "    bootstrapped_scores = []\n", "    rng = np.random.RandomState(rng_seed)\n", "    for i in range(n_bootstraps):\n", "        indices = rng.randint(0, len(y_pred) - 1, len(y_pred))\n", "        if len(np.unique(y_true[indices])) < 2:\n", "            continue\n", "        score = roc_auc_score(y_true[indices], y_pred[indices])\n", "        bootstrapped_scores.append(score)\n", "    sorted_scores = np.array(bootstrapped_scores)\n", "    sorted_scores.sort()\n", "    confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n", "    confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n", "    return confidence_lower, confidence_upper\n", "def evaluate_model(model, data_loader):\n", "    model.eval()\n", "    total = 0\n", "    correct = 0\n", "    predicted_labels = []\n", "    test_labels = []\n", "    predicted_probabilities = []\n", "    patient_ids_list = []\n", "    with torch.no_grad():\n", "        for inputs, label, patient_ids in data_loader:\n", "            inputs = inputs.float().to(device)  \n", "            label = label.long().to(device)  \n", "            outputs = model(inputs)\n", "            probabilities = torch.softmax(outputs, dim=1)\n", "            _, predicted = torch.max(outputs, 1)\n", "            total += label.size(0)\n", "            correct += (predicted == label).sum().item()\n", "            predicted_probabilities.append(probabilities.cpu().numpy())\n", "            predicted_labels += predicted.tolist()\n", "            test_labels += label.tolist()\n", "            patient_ids_list += patient_ids\n", "    predicted_probabilities = np.concatenate(predicted_probabilities, axis=0)\n", "    return test_labels, predicted_labels, predicted_probabilities, patient_ids_list\n", "def find_multi_class_optimal_cutoffs(tpr, fpr, thresholds):\n", "    i = np.arange(len(tpr))\n", "    roc = pd.DataFrame({'tf': pd.Series(tpr-(1-fpr), index=i), 'thresholds': pd.Series(thresholds, index=i)})\n", "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n", "    return list(roc_t['thresholds'])\n", "def get_multi_class_predicted_labels_based_on_cutoff(probabilities, cutoffs):\n", "    return [np.argmax([p[i] > cutoffs[i] for i in range(3)]) for p in probabilities]\n", "def plot_roc_curve(y_true, y_pred_proba, model_name):\n", "    fpr = dict()\n", "    tpr = dict()\n", "    roc_auc = dict()\n", "    for i in range(3):\n", "        fpr[i], tpr[i], _ = roc_curve(y_true == i, y_pred_proba[:, i])\n", "        roc_auc[i] = auc(fpr[i], tpr[i])\n", "    plt.figure(figsize=(8, 6))\n", "    plt.plot(fpr[0], tpr[0], label=f'NCSE (area = {roc_auc[0]:.2f})')\n", "    plt.plot(fpr[1], tpr[1], label=f'ME (area = {roc_auc[1]:.2f})')\n", "    plt.plot(fpr[2], tpr[2], label=f'BI (area = {roc_auc[2]:.2f})')\n", "    plt.plot([0, 1], [0, 1], 'k--')\n", "    plt.xlabel('False Positive Rate')\n", "    plt.ylabel('True Positive Rate')\n", "    plt.title(f'ROC Curve - {model_name}')\n", "    plt.legend(loc='lower right')\n", "    plt.savefig(f'coh_ROC_{model_name}.eps', format='eps')\n", "    plt.show()\n", "def plot_confusion_matrix(y_true, y_pred, model_name):\n", "    matrix = confusion_matrix(y_true, y_pred)\n", "    plt.figure(figsize=(6, 5))\n", "    sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', cbar=False, vmin=0, vmax=50)\n", "    plt.xlabel('Predicted Label')\n", "    plt.ylabel('True Label')\n", "    plt.title(f'Confusion Matrix - {model_name}')\n", "    plt.savefig(f'coh_CM_{model_name}.eps', format='eps')\n", "    plt.show()\n", "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n", "from scipy.stats import sem\n", "def compute_corrected_metrics_from_cm(y_true, y_pred, y_pred_proba):\n", "    cm = confusion_matrix(y_true, y_pred)\n", "    classwise_metrics = []\n", "    total_samples = len(y_true)\n", "    for i in range(3):\n", "        tp = cm[i, i]\n", "        fn = sum(cm[i, :]) - tp\n", "        fp = sum(cm[:, i]) - tp\n", "        tn = total_samples - (tp + fn + fp)\n", "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n", "        precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n", "        recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n", "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n", "        classwise_metrics.append({\n", "            'accuracy': accuracy,\n", "            'f1': f1,\n", "            'precision': precision,\n", "            'recall': recall,\n", "            'tn': tn,\n", "            'tp': tp,\n", "            'fp': fp,\n", "            'fn': fn\n", "        })\n", "    overall_accuracy = accuracy_score(y_true, y_pred)\n", "    overall_f1 = f1_score(y_true, y_pred, average='macro')\n", "    overall_precision = precision_score(y_true, y_pred, average='macro')\n", "    overall_recall = recall_score(y_true, y_pred, average='macro')\n", "    overall_auc = roc_auc_score(y_true, y_pred_proba, average='macro', multi_class='ovr')\n", "    return {\n", "        'overall': {\n", "            'accuracy': overall_accuracy,\n", "            'f1': overall_f1,\n", "            'precision': overall_precision,\n", "            'recall': overall_recall,\n", "            'auc': overall_auc\n", "        },\n", "        'classwise': classwise_metrics\n", "    }\n", "def confidence_interval(data):\n", "    n = len(data)\n", "    m = mean(data)\n", "    std_err = sem(data)\n", "    ci = std_err * t.ppf((1 + 0.95) / 2, n - 1)\n", "    return (m - ci, m + ci)\n", "from sklearn.utils import resample\n", "def bootstrap_ci(y_true, y_pred, y_pred_proba, metric_function, label=None, n_bootstrap=1000, alpha=0.05):\n", "    \"\"\"Compute the (1-alpha) confidence interval of the metric using bootstrap.\"\"\"\n", "    bootstrap_samples = np.random.choice(len(y_true), size=(n_bootstrap, len(y_true)), replace=True)\n", "    y_true_array = np.array(y_true)\n", "    if label is not None:  \n", "        binary_true = (y_true_array == label).astype(int)\n", "        stats = [metric_function(binary_true[indices], y_pred_proba[indices, label]) for indices in bootstrap_samples]\n", "    elif y_pred is not None:  \n", "        stats = [metric_function(y_true_array[indices], y_pred[indices]) for indices in bootstrap_samples]\n", "    else:  \n", "        stats = [metric_function(y_true_array[indices], y_pred_proba[indices]) for indices in bootstrap_samples]\n", "    return (np.percentile(stats, 100 * (alpha / 2.)), np.percentile(stats, 100 * (1 - alpha / 2.)))\n", "def bootstrap_ci_for_auc(y_true, y_pred_proba, label, n_bootstrap=1000, alpha=0.05):\n", "    \"\"\"Compute the (1-alpha) confidence interval of the AUC using bootstrap for a specific class.\"\"\"\n", "    bootstrap_samples = np.random.choice(len(y_true), size=(n_bootstrap, len(y_true)), replace=True)\n", "    y_true_array = np.array(y_true)\n", "    binary_true = (y_true_array == label).astype(int)\n", "    auc_stats = [roc_auc_score(binary_true[indices], y_pred_proba[indices, label]) for indices in bootstrap_samples]\n", "    return (np.percentile(auc_stats, 100 * (alpha / 2.)), np.percentile(auc_stats, 100 * (1 - alpha / 2.)))\n", "def bootstrap_ci_classwise_metric(y_true, y_pred, metric_function, label, n_bootstrap=1000, alpha=0.05):\n", "    \"\"\"Compute the (1-alpha) confidence interval of the metric using bootstrap for a specific class.\"\"\"\n", "    indices = np.arange(len(y_true))  \n", "    y_true_binary = (np.array(y_true) == label).astype(int)\n", "    y_pred_binary = (np.array(y_pred) == label).astype(int)\n", "    stats = []\n", "    for _ in range(n_bootstrap):\n", "        resampled_indices = resample(indices)\n", "        stats.append(metric_function(y_true_binary[resampled_indices], y_pred_binary[resampled_indices]))\n", "    return (np.percentile(stats, 100 * (alpha / 2.)), np.percentile(stats, 100 * (1 - alpha / 2.)))\n", "def bootstrap_ci_classwise_auc(y_true, y_pred_proba, label, n_bootstrap=1000, alpha=0.05):\n", "    \"\"\"Compute the (1-alpha) confidence interval of the AUC using bootstrap for a specific class.\"\"\"\n", "    indices = np.arange(len(y_true))  \n", "    y_true_binary = (np.array(y_true) == label).astype(int)\n", "    auc_stats = []\n", "    for _ in range(n_bootstrap):\n", "        resampled_indices = resample(indices)\n", "        auc_stats.append(roc_auc_score(y_true_binary[resampled_indices], y_pred_proba[resampled_indices, label]))\n", "    return (np.percentile(auc_stats, 100 * (alpha / 2.)), np.percentile(auc_stats, 100 * (1 - alpha / 2.)))\n", "def compute_classwise_auc(y_true, y_pred_proba):\n", "    class_aucs = []\n", "    for i in range(3):\n", "        binary_y_true = np.where(y_true == i, 1, 0)\n", "        class_aucs.append(roc_auc_score(binary_y_true, y_pred_proba[:, i]))\n", "    return class_aucs"]}, {"cell_type": "code", "execution_count": null, "id": "919caaed-e38e-4deb-8275-90d465044f20", "metadata": {}, "outputs": [], "source": ["folder_path = \"D:/LOC_matrix/\" \n", "dataset = []\n", "temp_data_epilepsy = defaultdict(lambda: [None]*5)\n", "temp_data_tme = defaultdict(lambda: [None]*5)\n", "temp_data_drug = defaultdict(lambda: [None]*5)\n", "temp_data_control = defaultdict(lambda: [None]*5)\n", "frequency_bands = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n", "frequency_bands_dict = {band: i for i, band in enumerate(frequency_bands)}  \n", "epilepsy_path = os.path.join(folder_path, \"epilepsy_rev\")\n", "epilepsy_label = 0\n", "for file in os.listdir(epilepsy_path):\n", "    if not file.endswith(\".mat\"):\n", "        continue\n", "    match = re.search(r\"(\\w+)_([a-z\\d]+)\\.mat\", file)\n", "    if match is None:\n", "        continue\n", "    frequency_band, patient_number = match.group(1, 2)\n", "    file_path = os.path.join(epilepsy_path, file)\n", "    mat_data = io.loadmat(file_path)\n", "    data = np.array(mat_data['data'])\n", "    temp_data_epilepsy[patient_number][frequency_bands_dict[frequency_band]] = data\n", "tme_path = os.path.join(folder_path, \"tme_rev\")\n", "tme_label = 1\n", "for file in os.listdir(tme_path):\n", "    if not file.endswith(\".mat\"):\n", "        continue\n", "    match = re.search(r\"(\\w+)_([a-z\\d]+)\\.mat\", file)\n", "    if match is None:\n", "        continue\n", "    frequency_band, patient_number = match.group(1, 2)\n", "    file_path = os.path.join(tme_path, file)\n", "    mat_data = io.loadmat(file_path)\n", "    data = np.array(mat_data['data'])\n", "    temp_data_tme[patient_number][frequency_bands_dict[frequency_band]] = data\n", "drug_path = os.path.join(folder_path, \"drug_rev\")\n", "drug_label = 2\n", "for file in os.listdir(drug_path):\n", "    if not file.endswith(\".mat\"):\n", "        continue\n", "    match = re.search(r\"(\\w+)_([a-z\\d]+)\\.mat\", file)\n", "    if match is None:\n", "        continue\n", "    frequency_band, patient_number = match.group(1, 2)\n", "    file_path = os.path.join(drug_path, file)\n", "    mat_data = io.loadmat(file_path)\n", "    data = np.array(mat_data['data'])\n", "    temp_data_drug[patient_number][frequency_bands_dict[frequency_band]] = data\n", "for patient_number, data in temp_data_epilepsy.items():\n", "    for band in frequency_bands:\n", "        for i in range(19):  \n", "            data[frequency_bands_dict[band]][:i+1, i:] = 0  \n", "    dataset.append((np.stack(data, axis=0), epilepsy_label, patient_number))\n", "for patient_number, data in temp_data_tme.items():\n", "    for band in frequency_bands:\n", "        for i in range(19):  \n", "            data[frequency_bands_dict[band]][:i+1, i:] = 0  \n", "    dataset.append((np.stack(data, axis=0), tme_label, patient_number))\n", "for patient_number, data in temp_data_drug.items():\n", "    for band in frequency_bands:\n", "        for i in range(19):  \n", "            data[frequency_bands_dict[band]][:i+1, i:] = 0  \n", "    dataset.append((np.stack(data, axis=0), drug_label, patient_number))"]}, {"cell_type": "code", "execution_count": null, "id": "d2907023-b9db-4444-841b-445c54af0455", "metadata": {}, "outputs": [], "source": ["folder_path = \"D:/LOC_matrix/\" \n", "dataset_prospective = []\n", "temp_data_epilepsy = defaultdict(lambda: [None]*5)\n", "temp_data_tme = defaultdict(lambda: [None]*5)\n", "temp_data_drug = defaultdict(lambda: [None]*5)\n", "temp_data_control = defaultdict(lambda: [None]*5)\n", "frequency_bands = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n", "frequency_bands_dict = {band: i for i, band in enumerate(frequency_bands)}  \n", "epilepsy_path = os.path.join(folder_path, \"epilepsy_rev_pro\")\n", "epilepsy_label = 0\n", "for file in os.listdir(epilepsy_path):\n", "    if not file.endswith(\".mat\"):\n", "        continue\n", "    match = re.search(r\"(\\w+)_([a-z\\d]+)\\.mat\", file)\n", "    if match is None:\n", "        continue\n", "    frequency_band, patient_number = match.group(1, 2)\n", "    file_path = os.path.join(epilepsy_path, file)\n", "    mat_data = io.loadmat(file_path)\n", "    data = np.array(mat_data['data'])\n", "    temp_data_epilepsy[patient_number][frequency_bands_dict[frequency_band]] = data\n", "tme_path = os.path.join(folder_path, \"tme_rev_pro\")\n", "tme_label = 1\n", "for file in os.listdir(tme_path):\n", "    if not file.endswith(\".mat\"):\n", "        continue\n", "    match = re.search(r\"(\\w+)_([a-z\\d]+)\\.mat\", file)\n", "    if match is None:\n", "        continue\n", "    frequency_band, patient_number = match.group(1, 2)\n", "    file_path = os.path.join(tme_path, file)\n", "    mat_data = io.loadmat(file_path)\n", "    data = np.array(mat_data['data'])\n", "    temp_data_tme[patient_number][frequency_bands_dict[frequency_band]] = data\n", "drug_path = os.path.join(folder_path, \"drug_rev_pro\")\n", "drug_label = 2\n", "for file in os.listdir(drug_path):\n", "    if not file.endswith(\".mat\"):\n", "        continue\n", "    match = re.search(r\"(\\w+)_([a-z\\d]+)\\.mat\", file)\n", "    if match is None:\n", "        continue\n", "    frequency_band, patient_number = match.group(1, 2)\n", "    file_path = os.path.join(drug_path, file)\n", "    mat_data = io.loadmat(file_path)\n", "    data = np.array(mat_data['data'])\n", "    temp_data_drug[patient_number][frequency_bands_dict[frequency_band]] = data\n", "for patient_number, data in temp_data_epilepsy.items():\n", "    for band in frequency_bands:\n", "        for i in range(19):  \n", "            data[frequency_bands_dict[band]][:i+1, i:] = 0  \n", "    dataset_prospective.append((np.stack(data, axis=0), epilepsy_label, patient_number))\n", "for patient_number, data in temp_data_tme.items():\n", "    for band in frequency_bands:\n", "        for i in range(19):  \n", "            data[frequency_bands_dict[band]][:i+1, i:] = 0  \n", "    dataset_prospective.append((np.stack(data, axis=0), tme_label, patient_number))\n", "for patient_number, data in temp_data_drug.items():\n", "    for band in frequency_bands:\n", "        for i in range(19):  \n", "            data[frequency_bands_dict[band]][:i+1, i:] = 0  \n", "    dataset_prospective.append((np.stack(data, axis=0), drug_label, patient_number))\n"]}, {"cell_type": "code", "execution_count": null, "id": "49a3b84a-b0f2-496b-bb2f-3dbff944b370", "metadata": {}, "outputs": [], "source": ["class EEGDataset(Dataset):\n", "    def __init__(self, data, labels, patient_ids):\n", "        self.data = data\n", "        self.labels = labels\n", "        self.patient_ids = patient_ids\n", "    def __len__(self):\n", "        return len(self.data)\n", "    def __getitem__(self, idx):\n", "        return self.data[idx], self.labels[idx], self.patient_ids[idx]\n"]}, {"cell_type": "code", "execution_count": null, "id": "029b7947-abc1-4f86-86f0-03e0e55c458d", "metadata": {}, "outputs": [], "source": ["def output_size_after_conv(input_size, kernel_size, stride=1, padding=1):\n", "    return int((input_size - kernel_size + 2 * padding) / stride + 1)\n", "def output_size_after_maxpool(input_size, kernel_size, stride=None):\n", "    if stride is None:\n", "        stride = kernel_size\n", "    return int((input_size - kernel_size) / stride + 1)\n", "class DynamicEEGCNN(nn.Module):\n", "    def __init__(self, num_blocks=2, dropout_rate=0.20, kernel_size=3):\n", "        super(DynamicEEGCNN, self).__init__()\n", "        channels = [5, 32, 64, 128, 256]\n", "        self.blocks = nn.ModuleList()\n", "        input_size = 19\n", "        for i in range(num_blocks):\n", "            conv_size = output_size_after_conv(input_size, kernel_size)\n", "            pool_size = output_size_after_maxpool(conv_size, 2)\n", "            if pool_size < 1:\n", "                break\n", "            block = nn.Sequential(\n", "                nn.Conv2d(channels[i], channels[i+1], kernel_size=kernel_size, stride=1, padding=1),\n", "                nn.BatchNorm2d(channels[i+1]),\n", "                nn.LeakyReLU(),\n", "                nn.Conv2d(channels[i+1], channels[i+1], kernel_size=kernel_size, stride=1, padding=1),\n", "                nn.BatchNorm2d(channels[i+1]),\n", "                nn.LeakyReLU(),\n", "                nn.Dropout(dropout_rate),\n", "                nn.MaxPool2d(kernel_size=2),\n", "            )\n", "            self.blocks.append(block)\n", "            input_size = pool_size\n", "        final_size = int(input_size)\n", "        final_channel = channels[len(self.blocks)]\n", "        fc_input_size = final_channel * final_size * final_size\n", "        if kernel_size == 3:\n", "            self.fc1 = nn.Sequential(\n", "                nn.Linear(fc_input_size, 1024),\n", "                nn.LeakyReLU(),\n", "                nn.Dropout(dropout_rate)\n", "            )\n", "            self.fc2 = nn.Sequential(\n", "                nn.Linear(1024, 512),\n", "                nn.LeakyReLU(),\n", "                nn.Dropout(dropout_rate)\n", "            )\n", "            self.fc3 = nn.Linear(512, 3)\n", "    def forward(self, x):\n", "        for block in self.blocks:\n", "            x = block(x)\n", "        x = x.view(x.size(0), -1)\n", "        x = self.fc1(x)\n", "        x = self.fc2(x)\n", "        x = self.fc3(x)\n", "        return x\n"]}, {"cell_type": "code", "execution_count": null, "id": "d4cd896a-87dd-43a3-ad0d-50c54590b34f", "metadata": {"scrolled": true}, "outputs": [], "source": ["seed_value = 777  \n", "random.seed(seed_value)\n", "np.random.seed(seed_value)\n", "torch.manual_seed(77)\n", "torch.cuda.manual_seed(seed_value)\n", "torch.cuda.manual_seed_all(seed_value)\n", "torch.backends.cudnn.deterministic = True\n", "torch.backends.cudnn.benchmark = False\n", "param_grid = {\n", "    'learning_rate': [0.001],\n", "    'weight_decay': [1e-6],\n", "    'dropout_rate': [0.10],\n", "    'kernel_size': [3],\n", "    'num_blocks': [4]\n", "}\n", "predictions = defaultdict(list)\n", "external_predictions = defaultdict(list)\n", "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n", "for params in all_params:\n", "    best_results = {\n", "        'predicted_probabilities': None,\n", "        'test_labels': None,\n", "        'predicted_labels': None\n", "    }\n", "    best_results_per_fold = defaultdict(lambda: {\n", "        'predicted_probabilities': None,\n", "        'test_labels': None,\n", "        'predicted_labels': None,\n", "        'patient_ids': None\n", "    })\n", "    learning_rate = params['learning_rate']\n", "    weight_decay = params['weight_decay']\n", "    dropout_rate = params['dropout_rate']\n", "    kernel_size = params['kernel_size']\n", "    num_blocks = params['num_blocks']\n", "    print(f\"Training with params: {params}\")\n", "    train_batch_size = 256 \n", "    train_shuffle = True  \n", "    test_batch_size = 256  \n", "    test_shuffle = False  \n", "    num_epochs = 1000 \n", "    best_model_path = None\n", "    best_accuracy = 0.0\n", "    best_fold = None\n", "    k = 10 \n", "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=777) \n", "    fold_results = []  \n", "    all_test_labels = [] \n", "    all_predicted_labels = [] \n", "    all_predicted_probabilities = []    \n", "    data, labels, patient_ids = zip(*dataset)\n", "    data = np.array(data)\n", "    labels = np.array(labels)\n", "    for fold, (train_indices, test_indices) in enumerate(skf.split(data, labels)):\n", "        fold_patient_ids = [patient_ids[i] for i in test_indices] \n", "        fold_train_data, fold_train_labels = data[train_indices], labels[train_indices]\n", "        fold_test_data, fold_test_labels = data[test_indices], labels[test_indices]\n", "        fold_train_dataset = EEGDataset(fold_train_data, fold_train_labels, [patient_ids[i] for i in train_indices])\n", "        fold_test_dataset = EEGDataset(fold_test_data, fold_test_labels, [patient_ids[i] for i in test_indices])\n", "        fold_train_data_loader = DataLoader(fold_train_dataset, batch_size=train_batch_size, shuffle=train_shuffle)\n", "        fold_test_data_loader = DataLoader(fold_test_dataset, batch_size=test_batch_size, shuffle=test_shuffle)\n", "        model = DynamicEEGCNN(num_blocks=params['num_blocks'], dropout_rate=dropout_rate, kernel_size=kernel_size).to('cuda:0')\n", "        criterion = nn.CrossEntropyLoss()\n", "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n", "        best_test_accuracy = 0.0\n", "        for epoch in range(num_epochs):\n", "            total = 0\n", "            correct = 0\n", "            model.train()  \n", "            for inputs, label, patient_id_batch in fold_train_data_loader:\n", "                inputs = inputs.float().to('cuda:0')  \n", "                label = label.long().to('cuda:0')     \n", "                outputs = model(inputs)\n", "                loss = criterion(outputs, label)\n", "                optimizer.zero_grad()\n", "                loss.backward()\n", "                optimizer.step()\n", "                _, predicted = torch.max(outputs, 1)\n", "                total += label.size(0)\n", "                correct += (predicted == label).sum().item()\n", "            train_accuracy = correct / total\n", "            total = 0\n", "            correct = 0\n", "            model.eval()  \n", "            fold_predicted_labels = []\n", "            fold_test_labels = []\n", "            fold_predicted_probabilities = []\n", "            with torch.no_grad():\n", "                for inputs, label, patient_id_batch in fold_test_data_loader:  \n", "                    inputs = inputs.float().to('cuda:0')  \n", "                    label = label.long().to('cuda:0')     \n", "                    outputs = model(inputs)\n", "                    probabilities = torch.softmax(outputs, dim=1) \n", "                    _, predicted = torch.max(outputs, 1)\n", "                    total += label.size(0)\n", "                    correct += (predicted == label).sum().item()\n", "                    fold_predicted_probabilities.append(probabilities.cpu().numpy())\n", "                    fold_predicted_labels += predicted.cpu().tolist()  \n", "                    fold_test_labels += label.cpu().tolist()          \n", "            fold_predicted_probabilities = np.concatenate(fold_predicted_probabilities, axis=0)\n", "            test_accuracy = correct / total\n", "            if test_accuracy > best_test_accuracy:\n", "                best_test_accuracy = test_accuracy\n", "                model_path = f'./LOC_slice_1_model_fold_{fold + 1}.pth'\n", "                torch.save(model.state_dict(), model_path)\n", "                if best_test_accuracy > best_accuracy:\n", "                    best_accuracy = best_test_accuracy\n", "                    best_model_path = model_path\n", "                    best_fold = fold\n", "                    best_results = {\n", "                        'predicted_probabilities': fold_predicted_probabilities,\n", "                        'test_labels': fold_test_labels,\n", "                        'predicted_labels': fold_predicted_labels\n", "                    }\n", "                best_results_per_fold[fold] = {\n", "                'predicted_probabilities': fold_predicted_probabilities,\n", "                'test_labels': fold_test_labels,\n", "                'predicted_labels': fold_predicted_labels,\n", "                'patient_ids': fold_patient_ids\n", "                }\n", "                best_predicted_probabilities = fold_predicted_probabilities\n", "                best_predicted_labels = fold_predicted_labels\n", "                best_test_labels = fold_test_labels   \n", "        all_predicted_probabilities.append(best_predicted_probabilities)\n", "        all_predicted_labels += best_predicted_labels\n", "        all_test_labels += best_test_labels \n", "        fold_results.append(best_test_accuracy) \n", "        print(f\"Fold {fold + 1}, Best Test Acc: {best_test_accuracy:.4f}\")\n", "    for fold, fold_data in best_results_per_fold.items():\n", "        fold_predicted_probabilities = fold_data['predicted_probabilities']\n", "        fold_test_labels = fold_data['test_labels']\n", "        fold_predicted_labels = fold_data['predicted_labels']\n", "        fold_patient_ids = fold_data['patient_ids']\n", "        for idx in range(len(fold_test_labels)):\n", "            predictions['DeepLearningModel'].append({\n", "                'ID': fold_patient_ids[idx],\n", "                'Fold': fold + 1,\n", "                'True_Label': fold_test_labels[idx],\n", "                'NCSE_Prob': fold_predicted_probabilities[idx][0],\n", "                'ME_Prob': fold_predicted_probabilities[idx][1],\n", "                'BI_Prob': fold_predicted_probabilities[idx][2]\n", "            })\n", "    df = pd.DataFrame(predictions['DeepLearningModel'])\n", "    csv_filename = f\"dl_predictions_150_original_dataset.csv\"\n", "    df.to_csv(csv_filename, index=False)\n", "    mean_accuracy = sum(fold_results) / len(fold_results)\n", "    print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n", "    n_classes = 3\n", "    all_predicted_probabilities = np.array(all_predicted_probabilities)\n", "    all_test_labels = np.array(all_test_labels)\n", "    y_test = label_binarize(all_test_labels, classes=np.unique(all_test_labels))\n", "    y_score = all_predicted_probabilities.reshape(-1, n_classes)\n", "    fpr = dict()\n", "    tpr = dict()\n", "    roc_auc = dict()\n", "    for i in range(n_classes):\n", "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n", "        roc_auc[i] = auc(fpr[i], tpr[i])\n", "    plt.rcParams['font.size'] = 12  \n", "    for i, label in enumerate(['NCSE', 'ME', 'BI']):\n", "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n", "        roc_auc[i] = auc(fpr[i], tpr[i])\n", "        confidence_lower, confidence_upper = bootstrap_auc(y_test[:, i], y_score[:, i])\n", "        plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {label} (AUC = {roc_auc[i]:.3f}, 95% CI: [{confidence_lower:.3f}, {confidence_upper:.3f}])')\n", "    plt.plot([0, 1], [0, 1], 'k--')\n", "    plt.xlim([0.0, 1.0])\n", "    plt.ylim([0.0, 1.05])\n", "    plt.xlabel('False Positive Rate')\n", "    plt.ylabel('True Positive Rate')\n", "    plt.title('Receiver Operating Characteristic to Multi-Class')\n", "    plt.legend(loc=\"lower right\")\n", "    plt.savefig(\"dl_ROC.eps\", format='eps')\n", "    plt.show()\n", "    plt.rcParams['font.size'] = 18 \n", "    labels_class = ['NCSE', 'ME', 'BI']  \n", "    conf_mat = confusion_matrix(all_test_labels, all_predicted_labels)\n", "    plt.figure(figsize=(10,10))\n", "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=labels_class, yticklabels=labels_class, vmin=0, vmax=50)\n", "    plt.xlabel('Predicted Label', fontsize=22)\n", "    plt.ylabel('True Label', fontsize=22)\n", "    plt.savefig(\"dl_confusion.eps\", format='eps')\n", "    plt.show()\n", "    n_classes = 3\n", "    optimal_thresholds = dict()\n", "    for i, label in enumerate(['NCSE', 'ME', 'BI']):\n", "        fpr[i], tpr[i], thresholds = roc_curve(y_test[:, i], y_score[:, i])\n", "        optimal_thresholds[i] = find_optimal_cutoff(tpr[i], fpr[i], thresholds)\n", "    data_prospective, labels_prospective, patient_ids_prospective = zip(*dataset_prospective)\n", "    data_prospective = np.array(data_prospective)\n", "    labels_prospective = np.array(labels_prospective)\n", "    prospective_dataset = EEGDataset(data_prospective, labels_prospective, patient_ids_prospective)\n", "    prospective_data_loader = DataLoader(prospective_dataset, batch_size=test_batch_size, shuffle=test_shuffle)\n", "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n", "    best_model = DynamicEEGCNN(num_blocks=num_blocks, dropout_rate=dropout_rate, kernel_size=kernel_size).to(device)\n", "    best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n", "    full_train_dataset = EEGDataset(data, labels, patient_ids)\n", "    full_train_data_loader = DataLoader(full_train_dataset, batch_size=train_batch_size, shuffle=train_shuffle)\n", "    criterion = nn.CrossEntropyLoss()\n", "    additional_epochs = [100]\n", "    best_prospective_accuracy = 0.0\n", "    best_prospective_epoch = 0\n", "    results = {}\n", "    for epochs in additional_epochs:\n", "        model = DynamicEEGCNN(num_blocks=num_blocks, dropout_rate=dropout_rate, kernel_size=kernel_size).to(device)\n", "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n", "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n", "        for epoch in range(epochs):\n", "            model.train()\n", "            for inputs, label, _ in full_train_data_loader:\n", "                inputs = inputs.float().to(device)\n", "                label = label.long().to(device)\n", "                outputs = model(inputs)\n", "                loss = criterion(outputs, label)\n", "                optimizer.zero_grad()\n", "                loss.backward()\n", "                optimizer.step()\n", "        test_labels, predicted_labels, predicted_probabilities, patient_ids = evaluate_model(model, prospective_data_loader)\n", "        prospective_accuracy = np.mean(np.array(test_labels) == np.array(predicted_labels))\n", "        if prospective_accuracy > best_prospective_accuracy:\n", "            best_prospective_accuracy = prospective_accuracy\n", "            best_prospective_epoch = epochs\n", "        results[epochs] = {\n", "            'test_labels': test_labels,\n", "            'predicted_labels': predicted_labels,\n", "            'predicted_probabilities': predicted_probabilities\n", "        }\n", "        for idx in range(len(test_labels)):\n", "            external_predictions['DeepLearningModel'].append({\n", "                'ID': patient_ids_prospective[idx],\n", "                'Fold': 'ExternalValidation',\n", "                'True_Label': test_labels[idx],\n", "                'NCSE_Prob': predicted_probabilities[idx][0],\n", "                'ME_Prob': predicted_probabilities[idx][1],\n", "                'BI_Prob': predicted_probabilities[idx][2]\n", "            })\n", "        df = pd.DataFrame(external_predictions['DeepLearningModel'])\n", "        csv_filename = f\"dl_predictions_after_{epochs}_epochs.csv\"\n", "        df.to_csv(csv_filename, index=False)\n", "        external_predictions['DeepLearningModel'].clear()  \n", "    labels_class = ['NCSE', 'ME', 'BI']  \n", "    n_classes = 3\n", "    for epochs, epoch_results in results.items():\n", "        predicted_probabilities = epoch_results['predicted_probabilities']\n", "        test_labels = epoch_results['test_labels']\n", "        y_test = label_binarize(test_labels, classes=np.unique(test_labels))\n", "        y_score = predicted_probabilities.reshape(-1, n_classes)\n", "        optimal_thresholds = dict()\n", "        plt.figure(figsize=(25, 8))\n", "        plt.subplot(1, 3, 1)  \n", "        fpr = dict()\n", "        tpr = dict()\n", "        roc_auc = dict()\n", "        for i, label in enumerate(['NCSE', 'ME', 'BI']):\n", "            fpr[i], tpr[i], thresholds = roc_curve(y_test[:, i], y_score[:, i])\n", "            roc_auc[i] = auc(fpr[i], tpr[i])\n", "            confidence_lower, confidence_upper = bootstrap_auc(y_test[:, i], y_score[:, i])\n", "            plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {label} (AUC = {roc_auc[i]:.3f}, 95% CI: [{confidence_lower:.3f}, {confidence_upper:.3f}])')\n", "            optimal_thresholds[i] = find_optimal_cutoff(tpr[i], fpr[i], thresholds)\n", "        plt.plot([0, 1], [0, 1], 'k--')\n", "        plt.xlim([0.0, 1.0])\n", "        plt.ylim([0.0, 1.05])\n", "        plt.xlabel('False Positive Rate')\n", "        plt.ylabel('True Positive Rate')\n", "        plt.title(f'Receiver Operating Characteristic after {epochs} Epochs')\n", "        plt.legend(loc=\"lower right\")\n", "        optimal_predicted_labels = np.zeros_like(y_score)\n", "        for i in range(n_classes):\n", "            optimal_predicted_labels[:, i] = y_score[:, i] > optimal_thresholds[i]\n", "        optimal_predicted_labels = np.argmax(optimal_predicted_labels, axis=1)\n", "        general_predicted_labels = np.argmax(y_score, axis=1)\n", "        labels_class = ['NCSE', 'ME', 'BI']\n", "        conf_mat_general = confusion_matrix(test_labels, general_predicted_labels)\n", "        plt.subplot(1, 3, 3)  \n", "        sns.heatmap(conf_mat_general, annot=True, fmt='d', cmap='Blues', xticklabels=labels_class, yticklabels=labels_class, vmin=0, vmax=10)\n", "        plt.xlabel('Predicted Label', fontsize=12)\n", "        plt.ylabel('True Label', fontsize=12)\n", "        plt.title(f'General Confusion Matrix after {epochs} Epochs', fontsize=14)\n", "        plt.tight_layout()  \n", "        plt.savefig(f\"dl_combined_after_{epochs}_epochs.eps\", format='eps')\n", "        plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "id": "e2d76962-a722-4580-905e-5dd60c92847c", "metadata": {}, "outputs": [], "source": ["vmin = 0\n", "vmax = 1.5\n", "model = DynamicEEGCNN(num_blocks=params['num_blocks'], dropout_rate=dropout_rate, kernel_size=kernel_size).to('cuda:0')\n", "data, labels, patient_ids = zip(*dataset)\n", "train_batch_size = 256\n", "train_shuffle = True\n", "test_batch_size = 256\n", "test_shuffle = False\n", "data = np.array(data)\n", "labels = np.array(labels)\n", "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=777)\n", "class_names = ['NCSE', 'ME', 'BI']\n", "original_labels = labels.copy()\n", "saliency_sums_all_folds = {(class_idx, band_idx): [] for class_idx in range(3) for band_idx in range(5)}\n", "saliency_values_all_folds = {(class_idx, band_idx): [] for class_idx in range(3) for band_idx in range(5)}\n", "for fold, (train_indices, test_indices) in enumerate(skf.split(data, original_labels)):\n", "    print(f\"Processing fold {fold + 1}...\")\n", "    fold_test_labels = original_labels[test_indices]\n", "    unique, counts = np.unique(fold_test_labels, return_counts=True)\n", "    print(\"Class distribution in this fold's test set:\")\n", "    for u, c in zip(unique, counts):\n", "        print(f\"Class {u}: {c} samples\")\n", "    saliency_sums = {(class_idx, band_idx): np.zeros_like(data[0][0]) for class_idx in range(3) for band_idx in range(5)}\n", "    sample_counts = {(class_idx, band_idx): 0 for class_idx in range(3) for band_idx in range(5)}\n", "    if isinstance(original_labels, torch.Tensor):\n", "        labels = original_labels.numpy()\n", "    else:\n", "        labels = original_labels\n", "    model.load_state_dict(torch.load( f'./LOC_slice_1_model_fold_{fold + 1}.pth'))\n", "    fold_test_data, fold_test_labels = data[test_indices], labels[test_indices]\n", "    fold_patient_ids = [patient_ids[i] for i in test_indices]\n", "    fold_test_dataset = EEGDataset(fold_test_data, fold_test_labels, fold_patient_ids)\n", "    fold_test_data_loader = DataLoader(fold_test_dataset, batch_size=test_batch_size, shuffle=test_shuffle)\n", "    model.eval()\n", "    model.requires_grad_()\n", "    device = next(model.parameters()).device\n", "    for inputs, labels, _ in fold_test_data_loader:\n", "        inputs = inputs.to(device)\n", "        labels = labels.to(device)\n", "        for i in range(inputs.size(0)):\n", "            class_idx = labels[i].item()\n", "            for band_idx, band_name in enumerate(frequency_bands):\n", "                input_tensor = inputs[i].unsqueeze(0).float()\n", "                mask = torch.zeros_like(input_tensor)\n", "                mask[0, band_idx] = 1\n", "                input_tensor *= mask\n", "                input_tensor.requires_grad_()\n", "                outputs = model(input_tensor)\n", "                score = outputs[0, class_idx]\n", "                score.backward()\n", "                saliency = input_tensor.grad.data.abs().squeeze().cpu().numpy()\n", "                saliency_band = saliency[band_idx]\n", "                saliency_sums[(class_idx, band_idx)] += saliency_band\n", "                saliency_values = [saliency_band[i][j] for i in range(19) for j in range(i+1, 19)]\n", "                avg_saliency = np.mean(saliency_values)\n", "                saliency_values_all_folds[(class_idx, band_idx)].append(avg_saliency)\n", "                sample_counts[(class_idx, band_idx)] += 1\n", "    for class_idx in range(3):\n", "        for band_idx in range(5):\n", "            if sample_counts[(class_idx, band_idx)] != 0:\n", "                average_saliency_band = saliency_sums[(class_idx, band_idx)] / sample_counts[(class_idx, band_idx)]\n", "                saliency_sums_all_folds[(class_idx, band_idx)].append(average_saliency_band)\n", "            else:\n", "                print(f\"No samples for class {class_idx} and band {band_idx}.\")\n", "average_saliencies = {(class_idx, band_idx): np.mean(saliency_sums_all_folds[(class_idx, band_idx)], axis=0) for class_idx in range(3) for band_idx in range(5)}\n", "all_saliencies_flat = np.concatenate([saliency.ravel() for saliency in average_saliencies.values()])\n", "min_val, max_val = all_saliencies_flat.min(), all_saliencies_flat.max()\n", "fig = plt.figure(figsize=(17, 15))\n", "gs = gridspec.GridSpec(3, len(frequency_bands) + 1, width_ratios=[1] * len(frequency_bands) + [0.05])\n", "gs.update(wspace=0.5)\n", "axes = []\n", "for class_idx in range(3):\n", "    for band_idx, band_name in enumerate(frequency_bands):\n", "        for i in range(19):\n", "            for j in range(i, 19):\n", "                average_saliencies[(class_idx, band_idx)][i][j] = 0\n", "        ax = plt.subplot(gs[class_idx, band_idx])\n", "        im = ax.imshow(average_saliencies[(class_idx, band_idx)], cmap='jet', vmin=0, vmax=1.5)\n", "        ax.set_title(f\"{class_names[class_idx]}, {band_name}\")\n", "        axes.append(ax)\n", "cbar_ax = plt.subplot(gs[:, -1])\n", "fig.colorbar(im, cax=cbar_ax, orientation='vertical', ticks=[0, 0.5, 1, 1.5])\n", "plt.tight_layout()\n", "plt.savefig(\"dl_all_saliency_plots_with_colorbar.eps\", format='eps')\n", "plt.show()\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.4"}}, "nbformat": 4, "nbformat_minor": 5}